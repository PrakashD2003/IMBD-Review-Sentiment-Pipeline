# Environment variables for the repo.
# Copy this file to .env and fill in the values.

# ==========================
# General App Config
# ==========================
SINGLE_FILE=false
N_PARTITIONS=3
PYTHONIOENCODING=utf-8

# ==========================
# S3 / DVC Storage Config
# ==========================
AWS_ACCESS_KEY_ID=""
AWS_SECRET_ACCESS_KEY=""
AWS_REGION=""
S3_DATA_BUCKET=""
S3_DATA_FILE_PREFIX_ENV=""
DVC_S3_BUCKET=""

# ==========================
# MLflow & DagsHub Config
# ==========================
MLFLOW_TRACKING_URI=""
MLFLOW_REGISTRY_URI=""

# DagsHub Personal Access Token auth
MLFLOW_TRACKING_USERNAME=""
MLFLOW_TRACKING_PASSWORD=""

DAGSHUB_REPO_OWNER_NAME=""
DAGSHUB_REPO_NAME=""

DAGSHUB_USERNAME=""
DAGSHUB_TOKEN=""

# ==========================
# Experiment & Model Names
# ==========================
EXPERIMENT_NAME=""
MODEL_NAME=""
VECTORIZER_NAME=""

# ===========================
# Dask Config
# ===========================
### Trainig Pipeline Variables ###
DASK_SCHEDULER_ADDRESS="scheduler:8786"
PYTHONPATH=/app
# Environment configuration for local Dask clusters
DASK_WORKERS = "1"
DASK_THREADS = "2"
DASK_MEMORY_LIMIT = "12GB"

# ======================================
# Production DVC TrainingManager Vars
# ======================================
# WORKSPACE_DIR=/app
# DVC_NO_SCM=true           # or false if you want SCM locally
# COMMIT_SHA
# BUILD_ID
# CONTAINER_IMAGE_TAG
# POD_NAMESPACE
# HOSTNAME
# AWS_REGION

